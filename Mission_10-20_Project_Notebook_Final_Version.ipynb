{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f42d94a7-c1aa-490d-90a4-f95ec4fa7d92",
   "metadata": {},
   "source": [
    "# Missions 10/20 Project: Text Classification on Tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68c4bc86",
   "metadata": {},
   "source": [
    "We are going to build an example of a text classification model using a dataset providing tweets and their sentiment about Covid-19.\n",
    "\n",
    "Here is the URL to the dataset that needs to be downloaded:\n",
    "https://www.kaggle.com/datasets/datatattle/covid-19-nlp-text-classification/code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "40dc77c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c385b29",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# The dataset is already split in a train and test set\n",
    "# The path needs to be changed depending on where the csv files are stored on your machine\n",
    "train = pd.read_csv(\"./Corona_NLP_train.csv\", encoding='latin-1')\n",
    "test = pd.read_csv('./Corona_NLP_test.csv', encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1a8dc3ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserName</th>\n",
       "      <th>ScreenName</th>\n",
       "      <th>Location</th>\n",
       "      <th>TweetAt</th>\n",
       "      <th>OriginalTweet</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3799</td>\n",
       "      <td>48751</td>\n",
       "      <td>London</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>@MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3800</td>\n",
       "      <td>48752</td>\n",
       "      <td>UK</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>advice Talk to your neighbours family to excha...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3801</td>\n",
       "      <td>48753</td>\n",
       "      <td>Vagabonds</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>Coronavirus Australia: Woolworths to give elde...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3802</td>\n",
       "      <td>48754</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>My food stock is not the only one which is emp...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3803</td>\n",
       "      <td>48755</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>Me, ready to go at supermarket during the #COV...</td>\n",
       "      <td>Extremely Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   UserName  ScreenName   Location     TweetAt  \\\n",
       "0      3799       48751     London  16-03-2020   \n",
       "1      3800       48752         UK  16-03-2020   \n",
       "2      3801       48753  Vagabonds  16-03-2020   \n",
       "3      3802       48754        NaN  16-03-2020   \n",
       "4      3803       48755        NaN  16-03-2020   \n",
       "\n",
       "                                       OriginalTweet           Sentiment  \n",
       "0  @MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...             Neutral  \n",
       "1  advice Talk to your neighbours family to excha...            Positive  \n",
       "2  Coronavirus Australia: Woolworths to give elde...            Positive  \n",
       "3  My food stock is not the only one which is emp...            Positive  \n",
       "4  Me, ready to go at supermarket during the #COV...  Extremely Negative  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae38760",
   "metadata": {},
   "source": [
    "The Usernames and Screennames have been replaced by numbers to keep their anonimity.\n",
    "\n",
    "Our focus is only on the last two columns since they represent our data and associated labels.\n",
    "\n",
    "Let's take a look at how much data we have:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "deaa3bc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41157, 6)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b02a61-ceaa-4fd3-a200-fb6de89f0fa8",
   "metadata": {},
   "source": [
    "With this in mind, we can start creating our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b4fe8c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty model in English\n",
    "nlp = spacy.blank(\"en\")\n",
    "\n",
    "# Add the TextCategorizer to the empty model using textcat_multilabel\n",
    "textcat = nlp.add_pipe(\"textcat_multilabel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a7c2ba67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neutral\n",
      "Positive\n",
      "Extremely Negative\n",
      "Negative\n",
      "Extremely Positive\n"
     ]
    }
   ],
   "source": [
    "# Find out exactly which values are in sentiments, which will be our labels\n",
    "sentiments = train['Sentiment']\n",
    "sentiments = sentiments.drop_duplicates()\n",
    "for value in sentiments:\n",
    "    print(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "42a4eef7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add our labels to the text classifier\n",
    "textcat.add_label(\"Neutral\")\n",
    "textcat.add_label(\"Positive\")\n",
    "textcat.add_label(\"Extremely Negative\")\n",
    "textcat.add_label(\"Negative\")\n",
    "textcat.add_label(\"Extremely Positive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "de10b309",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('@MeNyrbie @Phil_Gahan @Chrisitv https://t.co/iFz9FAn2Pa and https://t.co/xX6ghGFzCC and https://t.co/I2NlzdxNo8',\n",
       "  {'cats': {'Neutral': True,\n",
       "    'Positive': False,\n",
       "    'Extremely Negative': False,\n",
       "    'Negative': False,\n",
       "    'Extremely Positive': False}}),\n",
       " ('advice Talk to your neighbours family to exchange phone numbers create contact list with phone numbers of neighbours schools employer chemist GP set up online shopping accounts if poss adequate supplies of regular meds but not over order',\n",
       "  {'cats': {'Neutral': False,\n",
       "    'Positive': True,\n",
       "    'Extremely Negative': False,\n",
       "    'Negative': False,\n",
       "    'Extremely Positive': False}}),\n",
       " ('Coronavirus Australia: Woolworths to give elderly, disabled dedicated shopping hours amid COVID-19 outbreak https://t.co/bInCA9Vp8P',\n",
       "  {'cats': {'Neutral': False,\n",
       "    'Positive': True,\n",
       "    'Extremely Negative': False,\n",
       "    'Negative': False,\n",
       "    'Extremely Positive': False}})]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Convert our labels to the form that TextCategorizer requires\n",
    "train_texts = train['OriginalTweet'].values\n",
    "train_labels = [{'cats': {'Neutral': Sentiment == 'Neutral',\n",
    "                          'Positive': Sentiment == 'Positive',\n",
    "                          'Extremely Negative': Sentiment == 'Extremely Negative',\n",
    "                          'Negative': Sentiment == 'Negative',\n",
    "                          'Extremely Positive': Sentiment == 'Extremely Positive'}} \n",
    "                for Sentiment in train['Sentiment']] \n",
    "train_data = list(zip(train_texts, train_labels))\n",
    "train_data[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e344d7-6475-47ab-b1e8-c3f75c8a8009",
   "metadata": {},
   "source": [
    "**Now let's train it !**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2873d641",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'textcat_multilabel': 4954.34124961769}\n",
      "{'textcat_multilabel': 8577.840496189383}\n",
      "{'textcat_multilabel': 11523.869732122108}\n",
      "{'textcat_multilabel': 14053.386383053567}\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from spacy.util import minibatch\n",
    "from spacy.training.example import Example\n",
    "\n",
    "# We set some randomness to our data\n",
    "random.seed(1)\n",
    "spacy.util.fix_random_seed(1)\n",
    "\n",
    "# And start the optimization process\n",
    "optimizer = nlp.begin_training()\n",
    "\n",
    "losses = {}\n",
    "for epoch in range(4):\n",
    "    random.shuffle(train_data)\n",
    "    # Create the batch generator with a certain batch size\n",
    "    batches = minibatch(train_data, size=20)\n",
    "    # Iterate through minibatches\n",
    "    for batch in batches:\n",
    "        for OriginalTweet, Sentiment in batch:\n",
    "            doc = nlp.make_doc(OriginalTweet)\n",
    "            example = Example.from_dict(doc, Sentiment)\n",
    "            nlp.update([example], sgd=optimizer, losses=losses) # update the model's parameters with the observations made\n",
    "    print(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "cf651716",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Extremely Negative', 'Extremely Positive', 'Neutral']\n"
     ]
    }
   ],
   "source": [
    "#Quickly test our model on sentences we've come up with\n",
    "texts = [\"I hate everything about this situation, Covid makes me depressed\",\n",
    "         \"I love staying at home and watching Netflix all day\",\n",
    "         \"Today I saw a balloon\"]\n",
    "\n",
    "#Tokenize our test sentences so that the model can assimilate them\n",
    "docs = [nlp.tokenizer(text) for text in texts]\n",
    "    \n",
    "# Use textcat to get the predicted scores for each sentence in docs\n",
    "textcat = nlp.get_pipe('textcat_multilabel')\n",
    "scores = textcat.predict(docs)\n",
    "\n",
    "#Turn the probabilistic scores into actual predictions with .argmax\n",
    "predicted_labels = scores.argmax(axis=1)\n",
    "print([textcat.labels[label] for label in predicted_labels])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36664b55",
   "metadata": {},
   "source": [
    "The model seems to understand the general sentiment of our examples, although the first sentence should probably be associated with an Extremely Negative label."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ee501c",
   "metadata": {},
   "source": [
    "Now, let's evaluate our model by computing it's accuracy on our test set. To do that, we first need to compute the amount of true predictions the model has made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d283b3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's retrieve the tweets from our test set\n",
    "test_texts = test[\"OriginalTweet\"]\n",
    "docs_test = [nlp.tokenizer(test_text) for test_text in test_texts]\n",
    "\n",
    "#Make the predictions\n",
    "scores_test = textcat.predict(docs_test)\n",
    "predicted_labels_test = scores_test.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "92c7806f-81d7-4d69-b2b3-3aace548753d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Retrieve the actual labels associated with the predictions and turn them from an array into a list\n",
    "actual_labels_test = test[\"Sentiment\"].values\n",
    "actual_labels_test = actual_labels_test.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "678aa08b-195e-4e42-afb1-b720ea1f4091",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3798,)\n"
     ]
    }
   ],
   "source": [
    "#Check the size of the data to know how many predictions we have\n",
    "print(predicted_labels_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "85fc3286-00d1-4646-bc13-5d08fa58d0fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2620\n"
     ]
    }
   ],
   "source": [
    "#Turn the predicted numbers into the labels they are associated with\n",
    "predicted_labels_evaluate = [textcat.labels[label_new] for label_new in predicted_labels_test]\n",
    "\n",
    "#Compare each row step by step to find true predictions\n",
    "true_prediction = 0\n",
    "for x in range(0,3798):\n",
    "    if [predicted_labels_evaluate[x]] == [actual_labels_test[x]]:\n",
    "        true_prediction += 1\n",
    "        \n",
    "print(true_prediction)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "87d96b6a-d05e-4083-b93a-68a86c0138cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6586224233283057\n"
     ]
    }
   ],
   "source": [
    "#Compute our accuracy\n",
    "Accuracy = true_prediction/3978\n",
    "print(Accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "149eafff-bb19-4d54-bbb5-ae98a807ceeb",
   "metadata": {},
   "source": [
    "**In the end, even if our model is using the TextCategorizer function of the Spacy library, it is actually able to perform sentiment analysis simply because it was trained with \"positive\" and \"negative\" type labels.**\n",
    "\n",
    "Unfortunately, our model isn't performing good at all and takes a lot of time to train. If we were able to improve our program for it to train faster, we could increase the batch size and amount of epochs, which could lead to a better performing model. Using this approach we were already able, through different iterations, to go from an accuracy of 0.57 to 0.66, so there is some room for improvement !"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
